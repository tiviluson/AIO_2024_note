{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "WR3kjNWrqjRd",
   "metadata": {
    "id": "WR3kjNWrqjRd"
   },
   "source": [
    "### Mô tả bài toán\n",
    "Trong các câu hỏi của phần **Name Entity Recognition** chúng ta được cung cấp một tập dữ liệu nhỏ bao gồm hai chuỗi văn bản và các nhãn tương ứng trong đoạn code Python sau:\n",
    "\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740888912022-image.png?alt=media&token=a2f9b858-8eac-451e-83ca-c73a55fdd53e)\n",
    "\n",
    "### NER\n",
    "Mục tiêu của bài toán này là xây dựng một mô hình Name Entity Recognition, gồm 5 class:  \n",
    "0: B-Person  \n",
    "1: I-Person  \n",
    "2: B-Organization/Location  \n",
    "3: I--Organization/Location  \n",
    "4: O  \n",
    "5: <pad> - padding  \n",
    "với Baseline cụ thể như hình sau:  \n",
    "\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740888959365-image.png?alt=media&token=70c3182b-edac-4ec1-a6dc-bb35cc4e7e3f)\n",
    "\n",
    "Tất cả thông tin đều đã có ở trong phần mô tả, hãy đọc hiểu và trả lời các câu hỏi sau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qavTqc8A0haF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 218686,
     "status": "ok",
     "timestamp": 1740824876412,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "qavTqc8A0haF",
    "outputId": "84e9fec7-8c92-46c9-ae9c-865f94e0ae4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.17.0\n",
      "  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Collecting torch==2.2.0 (from torchtext==0.17.0)\n",
      "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\n",
      "Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
   "metadata": {
    "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22382432-34a8-474b-9519-af1168597ea1",
   "metadata": {
    "id": "22382432-34a8-474b-9519-af1168597ea1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "corpus = [\n",
    "    \"Satya Nadella is based in Washington\",\n",
    "    \"Demis Hassabis works at DeepMind\"\n",
    "]\n",
    "data_size = len(corpus)\n",
    "\n",
    "# 0: B-Person - 1: I-Person\n",
    "# 2: B-Organization/Location - 3: I--Organization/Location\n",
    "# 4: O\n",
    "labels = [[0, 1, 4, 4, 4, 2],\n",
    "          [0, 1, 4, 4, 2]]\n",
    "\n",
    "# Define the max vocabulary size and sequence length\n",
    "vocab_size = 12\n",
    "sequence_length = 6\n",
    "num_classes = 5 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1740825313427,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
    "outputId": "c7d4e7bb-3a78-4ce1-8b18-fdb3330563aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'satya': 10,\n",
       " 'nadella': 9,\n",
       " 'is': 8,\n",
       " 'in': 7,\n",
       " 'demis': 5,\n",
       " 'hassabis': 6,\n",
       " 'deepmind': 4,\n",
       " 'based': 3,\n",
       " 'at': 2,\n",
       " '<pad>': 1,\n",
       " 'washington': 11,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(corpus),\n",
    "                                  max_tokens=vocab_size,\n",
    "                                  specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192fcd6-d411-4312-afcd-88fe4e64a8b9",
   "metadata": {
    "id": "3192fcd6-d411-4312-afcd-88fe4e64a8b9"
   },
   "outputs": [],
   "source": [
    "# Tokenize and numericalize your samples\n",
    "def vectorize(text, vocab, sequence_length, sequence_label):\n",
    "    tokens = tokenizer(text)\n",
    "\n",
    "    token_ids = [vocab[token] for token in tokens][:sequence_length]\n",
    "    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    sequence_label = sequence_label + [5] * (sequence_length - len(tokens))\n",
    "    sequence_label = sequence_label[:sequence_length]\n",
    "\n",
    "    return torch.tensor(token_ids, dtype=torch.long), torch.tensor(sequence_label, dtype=torch.long)\n",
    "\n",
    "# Vectorize the samples\n",
    "sentence_vecs = []\n",
    "label_vecs = []\n",
    "for sentence, labels in zip(corpus, labels):\n",
    "    sentence_vec, labels_vec = vectorize(sentence, vocab, sequence_length, labels)\n",
    "    sentence_vecs.append(sentence_vec)\n",
    "    label_vecs.append(labels_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1189966-b5d0-4bbe-9805-712e206b533c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1740825313567,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "c1189966-b5d0-4bbe-9805-712e206b533c",
    "outputId": "179f5932-7ea3-4aa0-e41f-2b0b50ef2b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10,  9,  8,  3,  7, 11])\n",
      "tensor([5, 6, 0, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "for v in sentence_vecs:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e40856-0cc4-4f25-b704-05e9d4aaeb95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1740825313712,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "e3e40856-0cc4-4f25-b704-05e9d4aaeb95",
    "outputId": "14e2157a-415b-495e-d4e5-fc7278ec129e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 4, 4, 4, 2])\n",
      "tensor([0, 1, 4, 4, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "for v in label_vecs:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4c5571-1104-44a2-a066-2118f4861e9a",
   "metadata": {
    "id": "cd4c5571-1104-44a2-a066-2118f4861e9a"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8843b2-83e1-408f-b9d1-0f7983cd7c59",
   "metadata": {
    "id": "2c8843b2-83e1-408f-b9d1-0f7983cd7c59"
   },
   "outputs": [],
   "source": [
    "class POS_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 2)\n",
    "        custom_embedding_weight = torch.tensor([\n",
    "            [ 0.26, -1.31],\n",
    "            [ 0.72,  0.43],\n",
    "            [-0.67,  0.61],\n",
    "            [ 0.50,  0.50],\n",
    "            [-0.26, -0.10],\n",
    "            [ 1.29,  1.25],\n",
    "            [ 1.95,  1.18],\n",
    "            [-1.44, -1.89],\n",
    "            [-0.20,  0.88],\n",
    "            [-0.39,  1.07],\n",
    "            [ 0.32, -0.05],\n",
    "            [ 0.59, -0.98]\n",
    "        ])\n",
    "        self.embedding.weight = nn.Parameter(custom_embedding_weight)\n",
    "        print(\"Embedding weights:\")\n",
    "        print(self.embedding.weight)\n",
    "\n",
    "\n",
    "        # Custom RNN layer\n",
    "        self.recurrent = nn.RNN(2, 3, batch_first=True)\n",
    "        custom_rnn_weight_ih = torch.tensor([\n",
    "              [-0.07, -0.31],\n",
    "              [-0.28, -0.19],\n",
    "              [-0.23, -0.15]\n",
    "        ])\n",
    "        custom_rnn_weight_hh = torch.tensor([\n",
    "              [ 0.04,  0.37,  0.32],\n",
    "              [ 0.46,  0.54, -0.54],\n",
    "              [ 0.25, -0.02,  0.05]\n",
    "        ])\n",
    "\n",
    "        custom_rnn_bias_ih = torch.tensor([-0.47, -0.47,  0.50])\n",
    "        custom_rnn_bias_hh = torch.tensor([ 0.42, -0.50,  0.41])\n",
    "\n",
    "        self.recurrent.weight_ih_l0 = nn.Parameter(custom_rnn_weight_ih)\n",
    "        self.recurrent.weight_hh_l0 = nn.Parameter(custom_rnn_weight_hh)\n",
    "        self.recurrent.bias_ih_l0 = nn.Parameter(custom_rnn_bias_ih)\n",
    "        self.recurrent.bias_hh_l0 = nn.Parameter(custom_rnn_bias_hh)\n",
    "\n",
    "        print(\"RNN weights and biases:\")\n",
    "        print(self.recurrent.weight_ih_l0)\n",
    "        print(self.recurrent.weight_hh_l0)\n",
    "        print(self.recurrent.bias_ih_l0)\n",
    "        print(self.recurrent.bias_hh_l0)\n",
    "\n",
    "        # Custom fully connected layer\n",
    "        self.fc = nn.Linear(3, num_classes)\n",
    "        custom_fc_weight = torch.tensor([\n",
    "            [ 0.10,  0.53,  0.23],\n",
    "            [ 0.34,  0.32, -0.36],\n",
    "            [ 0.24, -0.35,  0.29],\n",
    "            [-0.28,  0.10, -0.18],\n",
    "            [ 0.39,  0.15,  0.49],\n",
    "            [-0.57,  0.35,  0.54]\n",
    "        ])\n",
    "        self.fc.weight = nn.Parameter(custom_fc_weight)\n",
    "        custom_fc_bias = torch.tensor([[-0.13,  0.20,  0.13,  0.42, -0.22,  0.37]])\n",
    "        self.fc.bias = nn.Parameter(custom_fc_bias)\n",
    "        print(\"FC weights:\")\n",
    "        print(self.fc.weight)\n",
    "        print(\"FC bias:\")\n",
    "        print(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(f\"Input shape: {x.shape}\")\n",
    "        x = self.embedding(x)\n",
    "        print(f\"After embedding shape: {x.shape}\")\n",
    "        x, _ = self.recurrent(x)\n",
    "        print(f\"After RNN shape: {x.shape}\")\n",
    "        x = self.fc(x)\n",
    "        print(f\"After FC shape: {x.shape}\")\n",
    "        print(x)\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print(f\"After permute shape: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028e52e-bee4-42f7-875a-f963218c80c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1740825693189,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "2028e52e-bee4-42f7-875a-f963218c80c5",
    "outputId": "6969af06-960f-46ef-fce7-b9f3f986e072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2600, -1.3100],\n",
      "        [ 0.7200,  0.4300],\n",
      "        [-0.6700,  0.6100],\n",
      "        [ 0.5000,  0.5000],\n",
      "        [-0.2600, -0.1000],\n",
      "        [ 1.2900,  1.2500],\n",
      "        [ 1.9500,  1.1800],\n",
      "        [-1.4400, -1.8900],\n",
      "        [-0.2000,  0.8800],\n",
      "        [-0.3900,  1.0700],\n",
      "        [ 0.3200, -0.0500],\n",
      "        [ 0.5900, -0.9800]], requires_grad=True)\n",
      "RNN weights and biases:\n",
      "Parameter containing:\n",
      "tensor([[-0.0700, -0.3100],\n",
      "        [-0.2800, -0.1900],\n",
      "        [-0.2300, -0.1500]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0400,  0.3700,  0.3200],\n",
      "        [ 0.4600,  0.5400, -0.5400],\n",
      "        [ 0.2500, -0.0200,  0.0500]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4700, -0.4700,  0.5000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4200, -0.5000,  0.4100], requires_grad=True)\n",
      "FC weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.1000,  0.5300,  0.2300],\n",
      "        [ 0.3400,  0.3200, -0.3600],\n",
      "        [ 0.2400, -0.3500,  0.2900],\n",
      "        [-0.2800,  0.1000, -0.1800],\n",
      "        [ 0.3900,  0.1500,  0.4900],\n",
      "        [-0.5700,  0.3500,  0.5400]], requires_grad=True)\n",
      "FC bias:\n",
      "Parameter containing:\n",
      "tensor([[-0.1300,  0.2000,  0.1300,  0.4200, -0.2200,  0.3700]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = POS_Model(vocab_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jx21PDGVElbb",
   "metadata": {
    "id": "jx21PDGVElbb"
   },
   "source": [
    "# Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910680f9-acb5-493e-a194-a3f18f4788f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1740825693720,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "910680f9-acb5-493e-a194-a3f18f4788f0",
    "outputId": "8da19887-9240-475f-a43b-f16175a10c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 6])\n",
      "After embedding shape: torch.Size([1, 6, 2])\n",
      "After RNN shape: torch.Size([1, 6, 3])\n",
      "After FC shape: torch.Size([1, 6, 6])\n",
      "tensor([[[-0.3919, -0.3171,  0.5895,  0.2339, -0.0224,  0.5002],\n",
      "         [-0.5143, -0.4956,  0.5719,  0.3103, -0.1750,  0.6450],\n",
      "         [-0.5387, -0.4904,  0.5579,  0.3242, -0.2123,  0.6228],\n",
      "         [-0.5538, -0.4547,  0.5486,  0.3258, -0.2327,  0.5626],\n",
      "         [-0.3275, -0.2517,  0.7864,  0.0566,  0.2581,  0.3234],\n",
      "         [-0.4223, -0.3168,  0.7369,  0.1264,  0.1089,  0.3569]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "After permute shape: torch.Size([1, 6, 6])\n",
      "torch.Size([1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([[10, 9, 8, 3, 7, 11]])\n",
    "output = model(data)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JVq-nYL5q8VE",
   "metadata": {
    "id": "JVq-nYL5q8VE"
   },
   "source": [
    "## M08NER01\n",
    "### Câu hỏi\n",
    "Output shape của model RNN là?  \n",
    "A.\n",
    "```\n",
    "(1, 6, 2)\n",
    "```\n",
    "B.\n",
    "```\n",
    "(1, 4, 2)\n",
    "```\n",
    "C.\n",
    "```\n",
    "(1, 6, 3)\n",
    "```\n",
    "D.\n",
    "```\n",
    "(1, 2, 4)\n",
    "```\n",
    "### Đáp án:\n",
    "C (batch_size, seq_len, hidden_state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GweYjC_xrbw-",
   "metadata": {
    "id": "GweYjC_xrbw-"
   },
   "source": [
    "## M08NER02\n",
    "### Câu hỏi\n",
    "Output shape của FC layer là?  \n",
    "A.\n",
    "```\n",
    "(1, 6, 6)\n",
    "```\n",
    "B.\n",
    "```\n",
    "(1, 6, 3)\n",
    "```\n",
    "C\n",
    "```\n",
    "(1, 3, 6)\n",
    "```\n",
    "D.\n",
    "```\n",
    "(1, 3, 3)\n",
    "```\n",
    "### Đáp án:\n",
    "A (batch_size, seq_len, nums_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s3fTzPkTR1VS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740825694426,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "s3fTzPkTR1VS",
    "outputId": "88956429-00d4-4f9f-d975-0ae2071466fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 1])\n",
      "After embedding shape: torch.Size([1, 1, 2])\n",
      "After RNN shape: torch.Size([1, 1, 3])\n",
      "After FC shape: torch.Size([1, 1, 6])\n",
      "tensor([[[-0.3919, -0.3171,  0.5895,  0.2339, -0.0224,  0.5002]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "After permute shape: torch.Size([1, 6, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5922], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model(torch.tensor([[10]]))\n",
    "sum(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LgHGrKGSr-SF",
   "metadata": {
    "id": "LgHGrKGSr-SF"
   },
   "source": [
    "## M08NER03\n",
    "### Câu hỏi\n",
    "Hãy dùng token đầu tiên của sample 1 tính toán forward và trả về output cuối cùng. Dưới đây, đâu là kết quả tổng tất cả các phần tử trong vector output đó.   \n",
    "A. 0.5624\n",
    "B. 0.5922\n",
    "C. 0.6473\n",
    "D. 0.6850\n",
    "### Đáp án:\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8gTJ7yNlM2W0",
   "metadata": {
    "id": "8gTJ7yNlM2W0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
