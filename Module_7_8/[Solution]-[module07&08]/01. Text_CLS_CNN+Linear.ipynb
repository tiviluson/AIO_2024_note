{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKLavLUBphEt"
   },
   "source": [
    "# Mô tả bài toán\n",
    "Trong các câu hỏi của phần **Text Classification**, **POS tagging**, chúng ta được cung cấp một tập dữ liệu nhỏ bao gồm hai chuỗi văn bản và các nhãn tương ứng trong đoạn code Python sau:\n",
    "\n",
    "```python\n",
    "corpus = [\n",
    "    \"you will get the low score\",\n",
    "    \"more study more lucky come to you\"\n",
    "]\n",
    "```\n",
    "Quá trình tiền xử lý dữ liệu, xây dựng vocabulary, embedding được trực quan hóa như hình sau:\n",
    "\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740886293065-image.png?alt=media&token=2a367e86-1eee-461e-b9ee-2fde92df5a42)\n",
    "\n",
    "## Text Classification\n",
    "Mục tiêu của bài toán này là xây dựng một mô hình phần loại text (0-Negative, 1-Positive) với Baseline cụ thể như hình sau:\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740886064549-image.png?alt=media&token=f061b3b2-195d-484b-8a1b-db5a42c4b6aa)\n",
    "Tất cả thông tin đều đã có ở trong phần mô tả, hãy đọc hiểu và trả lời các câu hỏi sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_DSNYXLGn3C"
   },
   "source": [
    "## Text Classification - CNN+Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 210012,
     "status": "ok",
     "timestamp": 1740821799566,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "L035tOjNkbR4",
    "outputId": "f5832a09-eb02-4635-ad40-0e6de4cd5f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.17.0\n",
      "  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Collecting torch==2.2.0 (from torchtext==0.17.0)\n",
      "  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\n",
      "Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n",
      "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSTqG7X8O82N"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjFoMLulF4jS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "corpus = [\n",
    "    \"you will get the low score\",\n",
    "    \"more study more lucky come to you\"\n",
    "]\n",
    "data_size = len(corpus)\n",
    "\n",
    "# 0: negative - 1: positive\n",
    "labels = [0, 1]\n",
    "\n",
    "# Define the max vocabulary size and sequence length\n",
    "vocab_size = 12\n",
    "sequence_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1740821912506,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "wPEte3mnF4c0",
    "outputId": "87a9dc7c-408c-497c-fdfe-0de17429b370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 11,\n",
       " 'the': 10,\n",
       " 'study': 9,\n",
       " 'score': 8,\n",
       " 'lucky': 7,\n",
       " 'low': 6,\n",
       " 'get': 5,\n",
       " 'come': 4,\n",
       " 'more': 2,\n",
       " '<pad>': 1,\n",
       " 'you': 3,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(examples):\n",
    "    for text in examples:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(yield_tokens(corpus),\n",
    "                                  max_tokens=vocab_size,\n",
    "                                  specials=[\"<unk>\", \"<pad>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Qcwb_J9F4aR"
   },
   "outputs": [],
   "source": [
    "# Tokenize and numericalize your samples\n",
    "def vectorize(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab[token] for token in tokens][:sequence_length]\n",
    "    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "# Vectorize the samples\n",
    "corpus_ids = []\n",
    "for sentence in corpus:\n",
    "    corpus_ids.append(vectorize(sentence, vocab, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740821912524,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "sYTUNNQfF4Xh",
    "outputId": "8c4ee157-15ea-4abf-95ee-f01368a4a9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  0,  5, 10,  6,  8])\n",
      "tensor([ 2,  9,  2,  7,  4, 11])\n"
     ]
    }
   ],
   "source": [
    "for v in corpus_ids:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09tC65tojhdK"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1740821912556,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "WrAKhUqPjhdK",
    "outputId": "a9dcd473-44e4-4a25-b129-c628798b2981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2600, -1.3100],\n",
      "        [ 0.7200,  0.4300],\n",
      "        [-0.6700,  0.6100],\n",
      "        [ 0.5000,  0.5000],\n",
      "        [-0.2600, -0.1000],\n",
      "        [ 1.2900,  1.2500],\n",
      "        [ 1.9500,  1.1800],\n",
      "        [-1.4400, -1.8900],\n",
      "        [-0.2000,  0.8800],\n",
      "        [-0.3900,  1.0700],\n",
      "        [ 0.3200, -0.0500],\n",
      "        [ 0.5900, -0.9800]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.3300, -0.2600],\n",
      "         [ 0.3800, -0.4600]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4000, -0.0600, -0.4400, -0.1000,  0.4300],\n",
      "        [-0.1900,  0.2800, -0.0400, -0.0100,  0.2300]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1800, 0.1800], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TCls_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 2)\n",
    "        custem_weight = torch.tensor([\n",
    "            [ 0.26, -1.31],\n",
    "            [ 0.72,  0.43],\n",
    "            [-0.67,  0.61],\n",
    "            [ 0.50,  0.50],\n",
    "            [-0.26, -0.10],\n",
    "            [ 1.29,  1.25],\n",
    "            [ 1.95,  1.18],\n",
    "            [-1.44, -1.89],\n",
    "            [-0.20,  0.88],\n",
    "            [-0.39,  1.07],\n",
    "            [ 0.32, -0.05],\n",
    "            [ 0.59, -0.98]\n",
    "        ])\n",
    "        self.embedding.weight = nn.Parameter(custem_weight)\n",
    "        print((self.embedding.weight))\n",
    "        self.conv1d = nn.Conv1d(2, 1, kernel_size=2)\n",
    "        custem_conv_weight = torch.tensor([\n",
    "            [[ 0.33, -0.26],\n",
    "            [0.38, -0.46]]\n",
    "        ])\n",
    "        self.conv1d.weight = nn.Parameter(custem_conv_weight)\n",
    "        custem_conv_weight = torch.tensor(\n",
    "            [-0.30]\n",
    "        )\n",
    "        self.conv1d.bias = nn.Parameter(custem_conv_weight)\n",
    "\n",
    "        print(self.conv1d.weight)\n",
    "        print(self.conv1d.bias)\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(5, num_classes)\n",
    "        custem_fc_weight = torch.tensor([\n",
    "          [ 0.40, -0.06, -0.44, -0.10,  0.43],\n",
    "          [-0.19,  0.28, -0.04, -0.01,  0.23]\n",
    "        ])\n",
    "        self.fc.weight = nn.Parameter(custem_fc_weight)\n",
    "        custem_fc_bias = torch.tensor(\n",
    "            [0.18, 0.18]\n",
    "        )\n",
    "        self.fc.bias = nn.Parameter(custem_fc_bias)\n",
    "\n",
    "        print(self.fc.weight)\n",
    "        print(self.fc.bias)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d(x)\n",
    "        print(x.shape)\n",
    "        print(f\"Output conv1d: {x}\")\n",
    "\n",
    "\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        print(f\"result: {x}\")\n",
    "        return x\n",
    "\n",
    "num_classes = 2\n",
    "model = TCls_Model(vocab_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzqMMVER0yNK"
   },
   "source": [
    "# Forward input 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740822670886,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "EkKJb31XjhdK",
    "outputId": "21850628-7005-4132-81f2-3480baf09b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 2])\n",
      "torch.Size([1, 2, 6])\n",
      "torch.Size([1, 1, 5])\n",
      "Output conv1d: tensor([[[ 0.5900, -1.6224,  0.5405, -1.2632,  0.4391]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 5])\n",
      "result: tensor([[ 0.5907, -0.2944]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "input_1 = torch.tensor([[3, 0, 5, 10, 6, 8]], dtype=torch.long)\n",
    "label_1 = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "output = model(input_1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5900, -1.6224,  0.5405, -1.2632,  0.4391]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = torch.nn.Conv1d(2, 1, kernel_size=2)\n",
    "conv.weight = torch.nn.Parameter(torch.tensor([[[0.33, -0.26], [0.38, -0.46]]]))\n",
    "conv.bias = torch.nn.Parameter(torch.tensor([-0.30]))\n",
    "embedding = nn.Embedding(12, 2)\n",
    "embedding.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0.26, -1.31],\n",
    "            [0.72, 0.43],\n",
    "            [-0.67, 0.61],\n",
    "            [0.50, 0.50],\n",
    "            [-0.26, -0.10],\n",
    "            [1.29, 1.25],\n",
    "            [1.95, 1.18],\n",
    "            [-1.44, -1.89],\n",
    "            [-0.20, 0.88],\n",
    "            [-0.39, 1.07],\n",
    "            [0.32, -0.05],\n",
    "            [0.59, -0.98],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "input = torch.tensor([[3, 0, 5, 10, 6, 8]], dtype=torch.long)\n",
    "input = embedding(input)\n",
    "input = input.permute(0, 2, 1)\n",
    "conv_out = conv(input)\n",
    "conv_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0A-lqKhpD5e"
   },
   "source": [
    "## M08CLS01\n",
    "### Câu hỏi\n",
    "Hãy xác định shape của **Input Embedding** và shape đầu vào của **convolution model Conv1d** lần lượt là?  \n",
    "\n",
    "A.\n",
    "```\n",
    "(1, 2, 6); (1, 6, 2)\n",
    "```  \n",
    "B.\n",
    "```\n",
    "(1, 6, 2); (1, 1, 2)\n",
    "```\n",
    "C.\n",
    "```\n",
    "(1, 6, 2); (1, 2, 6)\n",
    "```\n",
    "D.\n",
    "```\n",
    "(1, 2, 6); (1, 2, 1)\n",
    "```\n",
    "\n",
    "### Đáp án:\n",
    "C (Trước khi đưa vào Conv1D cần permute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gwp6hazpxxf"
   },
   "source": [
    "## M08CLS02\n",
    "### Câu hỏi\n",
    "**Input** của **FC layer** gồm bao nhiêu node?.  \n",
    "A. 3  \n",
    "B. 4  \n",
    "C. 5  \n",
    "D. 6  \n",
    "### Đáp án:\n",
    "C: 5 (Sử dụng công thức Convolution để tính)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayP29X5nqNeP"
   },
   "source": [
    "## M08CLS03\n",
    "### Câu hỏi\n",
    "Đâu là giá trị output của **conv1d** khi đưa **sample1** vào model (không quan trọng shape)?  \n",
    "A.\n",
    "```\n",
    "[0.59, -1.62,  0.54, -1.26,  0.44]\n",
    "```  \n",
    "B.\n",
    "```\n",
    "[0.73, -1.45, 0.28, -1.89, 0.61]\n",
    "```\n",
    "C.\n",
    "```\n",
    "[-0.15, 1.27, -0.92, 0.83, -1.34]\n",
    "```\n",
    "D.\n",
    "```\n",
    "[1.12, -0.67, 0.95, -1.08, 0.39]\n",
    "```\n",
    "\n",
    "Đáp án: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcbiabO6022i"
   },
   "source": [
    "# Forward input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740821912772,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "ZvI6gb38jhdL",
    "outputId": "884a9f08-79df-46c0-dc9c-d295143c919b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 2])\n",
      "torch.Size([1, 2, 6])\n",
      "torch.Size([1, 1, 5])\n",
      "Output conv1d: tensor([[[-0.6801, -0.1285,  0.9545, -1.3798, -0.1264]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 5])\n",
      "result: tensor([[-0.4207,  0.2198]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "input_2 = torch.tensor([[2, 9, 2, 7, 4, 11]], dtype=torch.long)\n",
    "label_2 = torch.tensor([1], dtype=torch.long)\n",
    "\n",
    "output = model(input_2)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PG2qWtE0b1R"
   },
   "source": [
    "# Sofmaxt output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1740821912947,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "YE0fGARc0b2I",
    "outputId": "530635e0-c976-4459-c049-7af4bd91c466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax của sample 1: [0.70787795 0.29212205]\n",
      "Softmax của sample 2: [0.34513352 0.65486648]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "# Output của sample 1 và sample 2\n",
    "output1 = np.array([0.5907, -0.2944])\n",
    "output2 = np.array([-0.4207,  0.2198])\n",
    "\n",
    "# Tính softmax\n",
    "softmax1 = softmax(output1)\n",
    "softmax2 = softmax(output2)\n",
    "\n",
    "print(\"Softmax của sample 1:\", softmax1)\n",
    "print(\"Softmax của sample 2:\", softmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740821912957,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "npVHuf9gQYKc",
    "outputId": "b82088c3-2da4-4eb2-b75b-9042f792b25f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0530114729878066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax1[0] + softmax2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7UeXr_P8A3U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
