{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKLavLUBphEt"
   },
   "source": [
    "# Mô tả bài toán\n",
    "Trong các câu hỏi của phần **Text Classification**, **POS tagging**, chúng ta được cung cấp một tập dữ liệu nhỏ bao gồm hai chuỗi văn bản và các nhãn tương ứng trong đoạn code Python sau:\n",
    "\n",
    "```python\n",
    "corpus = [\n",
    "    \"you will get the low score\",\n",
    "    \"more study more lucky come to you\"\n",
    "]\n",
    "```\n",
    "Quá trình tiền xử lý dữ liệu, xây dựng vocabulary, embedding được trực quan hóa như hình sau:\n",
    "\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740886293065-image.png?alt=media&token=2a367e86-1eee-461e-b9ee-2fde92df5a42)\n",
    "\n",
    "## Text Classification\n",
    "Mục tiêu của bài toán này là xây dựng một mô hình phần loại text (0-Negative, 1-Positive) với Baseline cụ thể như hình sau:\n",
    "![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740886064549-image.png?alt=media&token=f061b3b2-195d-484b-8a1b-db5a42c4b6aa)\n",
    "Tất cả thông tin đều đã có ở trong phần mô tả, hãy đọc hiểu và trả lời các câu hỏi sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_DSNYXLGn3C"
   },
   "source": [
    "## Text Classification - CNN+Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 210012,
     "status": "ok",
     "timestamp": 1740821799566,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "L035tOjNkbR4",
    "outputId": "f5832a09-eb02-4635-ad40-0e6de4cd5f19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.17.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Collecting torch==2.2.0 (from torchtext==0.17.0)\n",
      "  Using cached torch-2.2.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (1.26.4)\n",
      "Requirement already satisfied: torchdata==0.7.1 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (0.7.1)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (2024.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from tqdm->torchtext==0.17.0) (0.4.6)\n",
      "Using cached torch-2.2.0-cp311-cp311-win_amd64.whl (198.6 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0+cu128\n",
      "    Uninstalling torch-2.7.0+cu128:\n",
      "      Successfully uninstalled torch-2.7.0+cu128\n",
      "Successfully installed torch-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\miniconda3\\envs\\deeplearning\\Lib\\site-packages\\~~rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.7.0+cu128 requires torch==2.7.0+cu128, but you have torch 2.2.0 which is incompatible.\n",
      "torchvision 0.22.0+cu128 requires torch==2.7.0+cu128, but you have torch 2.2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSTqG7X8O82N"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HjFoMLulF4jS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\deeplearning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# import torchtext; torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "corpus = [\"you will get the low score\", \"more study more lucky come to you\"]\n",
    "data_size = len(corpus)\n",
    "\n",
    "# 0: negative - 1: positive\n",
    "labels = [0, 1]\n",
    "\n",
    "# Define the max vocabulary size and sequence length\n",
    "vocab_size = 12\n",
    "sequence_length = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1740821912506,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "wPEte3mnF4c0",
    "outputId": "87a9dc7c-408c-497c-fdfe-0de17429b370"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " 'low': 6,\n",
       " 'come': 4,\n",
       " '<pad>': 1,\n",
       " 'more': 2,\n",
       " 'you': 3,\n",
       " 'get': 5,\n",
       " 'lucky': 7,\n",
       " 'score': 8,\n",
       " 'study': 9,\n",
       " 'the': 10,\n",
       " 'to': 11}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define tokenizer function\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "def yield_tokens(corpus):\n",
    "    for sequence in corpus:\n",
    "        yield tokenizer(sequence)\n",
    "\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(corpus), max_tokens=vocab_size, specials=[\"<unk>\", \"<pad>\"]\n",
    ")\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"low\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Qcwb_J9F4aR"
   },
   "outputs": [],
   "source": [
    "# Tokenize and numericalize your samples\n",
    "def vectorize(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    token_ids = [vocab[token] for token in tokens][:sequence_length]\n",
    "    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n",
    "    return torch.tensor(token_ids, dtype=torch.long)\n",
    "\n",
    "# Vectorize the samples\n",
    "corpus_ids = []\n",
    "for sentence in corpus:\n",
    "    corpus_ids.append(vectorize(sentence, vocab, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740821912524,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "sYTUNNQfF4Xh",
    "outputId": "8c4ee157-15ea-4abf-95ee-f01368a4a9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  0,  5, 10,  6,  8])\n",
      "tensor([ 2,  9,  2,  7,  4, 11])\n"
     ]
    }
   ],
   "source": [
    "for v in corpus_ids:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09tC65tojhdK"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1740821912556,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "WrAKhUqPjhdK",
    "outputId": "a9dcd473-44e4-4a25-b129-c628798b2981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2600, -1.3100],\n",
      "        [ 0.7200,  0.4300],\n",
      "        [-0.6700,  0.6100],\n",
      "        [ 0.5000,  0.5000],\n",
      "        [-0.2600, -0.1000],\n",
      "        [ 1.2900,  1.2500],\n",
      "        [ 1.9500,  1.1800],\n",
      "        [-1.4400, -1.8900],\n",
      "        [-0.2000,  0.8800],\n",
      "        [-0.3900,  1.0700],\n",
      "        [ 0.3200, -0.0500],\n",
      "        [ 0.5900, -0.9800]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.3300, -0.2600],\n",
      "         [ 0.3800, -0.4600]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3000], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4000, -0.0600, -0.4400, -0.1000,  0.4300],\n",
      "        [-0.1900,  0.2800, -0.0400, -0.0100,  0.2300]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1800, 0.1800], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "class TCls_Model(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 2)\n",
    "        custem_weight = torch.tensor([\n",
    "            [ 0.26, -1.31],\n",
    "            [ 0.72,  0.43],\n",
    "            [-0.67,  0.61],\n",
    "            [ 0.50,  0.50],\n",
    "            [-0.26, -0.10],\n",
    "            [ 1.29,  1.25],\n",
    "            [ 1.95,  1.18],\n",
    "            [-1.44, -1.89],\n",
    "            [-0.20,  0.88],\n",
    "            [-0.39,  1.07],\n",
    "            [ 0.32, -0.05],\n",
    "            [ 0.59, -0.98]\n",
    "        ])\n",
    "        self.embedding.weight = nn.Parameter(custem_weight)\n",
    "        print((self.embedding.weight))\n",
    "        self.conv1d = nn.Conv1d(2, 1, kernel_size=2)\n",
    "        custom_conv_weight = torch.tensor([\n",
    "            [[ 0.33, -0.26],\n",
    "            [0.38, -0.46]]\n",
    "        ])\n",
    "        self.conv1d.weight = nn.Parameter(custom_conv_weight)\n",
    "        custom_conv_weight = torch.tensor(\n",
    "            [-0.30]\n",
    "        )\n",
    "        self.conv1d.bias = nn.Parameter(custom_conv_weight)\n",
    "\n",
    "        print(self.conv1d.weight)\n",
    "        print(self.conv1d.bias)\n",
    "\n",
    "\n",
    "        self.fc = nn.Linear(5, num_classes)\n",
    "        custom_fc_weights = torch.tensor([\n",
    "          [ 0.40, -0.06, -0.44, -0.10,  0.43],\n",
    "          [-0.19,  0.28, -0.04, -0.01,  0.23]\n",
    "        ])\n",
    "        self.fc.weight = nn.Parameter(custom_fc_weights)\n",
    "        custom_fc_bias = torch.tensor(\n",
    "            [0.18, 0.18]\n",
    "        )\n",
    "        self.fc.bias = nn.Parameter(custom_fc_bias)\n",
    "\n",
    "        print(self.fc.weight)\n",
    "        print(self.fc.bias)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        print(x.shape)\n",
    "        x = self.conv1d(x)\n",
    "        print(x.shape)\n",
    "        print(f\"Output conv1d: {x}\")\n",
    "\n",
    "\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        print(x.shape)\n",
    "        x = self.fc(x)\n",
    "        print(f\"result: {x}\")\n",
    "        return x\n",
    "\n",
    "num_classes = 2\n",
    "model = TCls_Model(vocab_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzqMMVER0yNK"
   },
   "source": [
    "# Forward input 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740822670886,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "EkKJb31XjhdK",
    "outputId": "21850628-7005-4132-81f2-3480baf09b2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 2])\n",
      "torch.Size([1, 2, 6])\n",
      "torch.Size([1, 1, 5])\n",
      "Output conv1d: tensor([[[ 0.5900, -1.6224,  0.5405, -1.2632,  0.4391]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 5])\n",
      "result: tensor([[ 0.5907, -0.2944]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "input_1 = torch.tensor([[3, 0, 5, 10, 6, 8]], dtype=torch.long)\n",
    "label_1 = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "output = model(input_1)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5900, -1.6224,  0.5405, -1.2632,  0.4391]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "conv = torch.nn.Conv1d(2, 1, kernel_size=2)\n",
    "conv.weight = torch.nn.Parameter(torch.tensor([[[0.33, -0.26], [0.38, -0.46]]]))\n",
    "conv.bias = torch.nn.Parameter(torch.tensor([-0.30]))\n",
    "embedding = nn.Embedding(12, 2)\n",
    "embedding.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0.26, -1.31],\n",
    "            [0.72, 0.43],\n",
    "            [-0.67, 0.61],\n",
    "            [0.50, 0.50],\n",
    "            [-0.26, -0.10],\n",
    "            [1.29, 1.25],\n",
    "            [1.95, 1.18],\n",
    "            [-1.44, -1.89],\n",
    "            [-0.20, 0.88],\n",
    "            [-0.39, 1.07],\n",
    "            [0.32, -0.05],\n",
    "            [0.59, -0.98],\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "input = torch.tensor([[3, 0, 5, 10, 6, 8]], dtype=torch.long)\n",
    "input = embedding(input)\n",
    "input = input.permute(0, 2, 1)\n",
    "conv_out = conv(input)\n",
    "conv_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0A-lqKhpD5e"
   },
   "source": [
    "## M08CLS01\n",
    "### Câu hỏi\n",
    "Hãy xác định shape của **Input Embedding** và shape đầu vào của **convolution model Conv1d** lần lượt là?  \n",
    "\n",
    "A.\n",
    "```\n",
    "(1, 2, 6); (1, 6, 2)\n",
    "```  \n",
    "B.\n",
    "```\n",
    "(1, 6, 2); (1, 1, 2)\n",
    "```\n",
    "C.\n",
    "```\n",
    "(1, 6, 2); (1, 2, 6)\n",
    "```\n",
    "D.\n",
    "```\n",
    "(1, 2, 6); (1, 2, 1)\n",
    "```\n",
    "\n",
    "### Đáp án:\n",
    "C (Trước khi đưa vào Conv1D cần permute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gwp6hazpxxf"
   },
   "source": [
    "## M08CLS02\n",
    "### Câu hỏi\n",
    "**Input** của **FC layer** gồm bao nhiêu node?.  \n",
    "A. 3  \n",
    "B. 4  \n",
    "C. 5  \n",
    "D. 6  \n",
    "### Đáp án:\n",
    "C: 5 (Sử dụng công thức Convolution để tính)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayP29X5nqNeP"
   },
   "source": [
    "## M08CLS03\n",
    "### Câu hỏi\n",
    "Đâu là giá trị output của **conv1d** khi đưa **sample1** vào model (không quan trọng shape)?  \n",
    "A.\n",
    "```\n",
    "[0.59, -1.62,  0.54, -1.26,  0.44]\n",
    "```  \n",
    "B.\n",
    "```\n",
    "[0.73, -1.45, 0.28, -1.89, 0.61]\n",
    "```\n",
    "C.\n",
    "```\n",
    "[-0.15, 1.27, -0.92, 0.83, -1.34]\n",
    "```\n",
    "D.\n",
    "```\n",
    "[1.12, -0.67, 0.95, -1.08, 0.39]\n",
    "```\n",
    "\n",
    "Đáp án: A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcbiabO6022i"
   },
   "source": [
    "# Forward input 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740821912772,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "ZvI6gb38jhdL",
    "outputId": "884a9f08-79df-46c0-dc9c-d295143c919b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6, 2])\n",
      "torch.Size([1, 2, 6])\n",
      "torch.Size([1, 1, 5])\n",
      "Output conv1d: tensor([[[-0.6801, -0.1285,  0.9545, -1.3798, -0.1264]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([1, 5])\n",
      "result: tensor([[-0.4207,  0.2198]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "input_2 = torch.tensor([[2, 9, 2, 7, 4, 11]], dtype=torch.long)\n",
    "label_2 = torch.tensor([1], dtype=torch.long)\n",
    "\n",
    "output = model(input_2)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PG2qWtE0b1R"
   },
   "source": [
    "# Sofmaxt output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 174,
     "status": "ok",
     "timestamp": 1740821912947,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "YE0fGARc0b2I",
    "outputId": "530635e0-c976-4459-c049-7af4bd91c466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax của sample 1: [0.70787795 0.29212205]\n",
      "Softmax của sample 2: [0.34513352 0.65486648]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x)\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "# Output của sample 1 và sample 2\n",
    "output1 = np.array([0.5907, -0.2944])\n",
    "output2 = np.array([-0.4207,  0.2198])\n",
    "\n",
    "# Tính softmax\n",
    "softmax1 = softmax(output1)\n",
    "softmax2 = softmax(output2)\n",
    "\n",
    "print(\"Softmax của sample 1:\", softmax1)\n",
    "print(\"Softmax của sample 2:\", softmax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740821912957,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "npVHuf9gQYKc",
    "outputId": "b82088c3-2da4-4eb2-b75b-9042f792b25f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0530114729878066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax1[0] + softmax2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7UeXr_P8A3U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
