{"cells":[{"cell_type":"markdown","source":["# Mô tả bài toán\n","Trong các câu hỏi của phần **Text Classification**, **POS tagging**, chúng ta được cung cấp một tập dữ liệu nhỏ bao gồm hai chuỗi văn bản và các nhãn tương ứng trong đoạn code Python sau:\n","\n","```python\n","corpus = [\n","    \"you will get the low score\",\n","    \"more study more lucky come to you\"\n","]\n","```\n","Quá trình tiền xử lý dữ liệu, xây dựng vocabulary, embedding được trực quan hóa như hình sau:\n","\n","![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740886293065-image.png?alt=media&token=2a367e86-1eee-461e-b9ee-2fde92df5a42)\n","\n","## POS tagging\n","Mục tiêu của bài toán này là xây dựng một mô hình Part-of-speech Tagging (gồm 4 class: 0: noun/pronoun - 1: verb - others - 2, padding - 3) với Baseline cụ thể như hình sau:\n","![image](https://firebasestorage.googleapis.com/v0/b/aivn-images.appspot.com/o/public%2F2025%2F3%2F2%2F1740887028471-image.png?alt=media&token=ef0404e3-0df3-464c-8778-d2121d9187d1)\n","\n","Tất cả thông tin đều đã có ở trong phần mô tả, hãy đọc hiểu và trả lời các câu hỏi sau:"],"metadata":{"id":"WR3kjNWrqjRd"}},{"cell_type":"markdown","metadata":{"id":"b_DSNYXLGn3C"},"source":["## POS tagging - Linear"]},{"cell_type":"code","source":["!pip install -U torchtext==0.17.0"],"metadata":{"id":"L035tOjNkbR4","outputId":"03fd844a-0ad3-4c53-e3cb-8426fb8c10f8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740823532036,"user_tz":-420,"elapsed":204468,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.17.0\n","  Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.6 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n","Collecting torch==2.2.0 (from torchtext==0.17.0)\n","  Downloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (1.26.4)\n","Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n","  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n","  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n","Downloading torchtext-0.17.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchdata, torchtext\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 triton-2.2.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"vSTqG7X8O82N"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HjFoMLulF4jS"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","# import torchtext; torchtext.disable_torchtext_deprecation_warning()\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","corpus = [\n","    \"you will get the low score\",\n","    \"more study more lucky come to you\"\n","]\n","data_size = len(corpus)\n","\n","# 0: noun/pronoun - 1: verb - others - 2\n","labels = [\n","    [0, 1, 1, 2, 2, 0],\n","    [2, 0, 2, 2, 1, 2, 0]\n","]\n","\n","# Define the max vocabulary size and sequence length\n","vocab_size = 12\n","sequence_length = 6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPEte3mnF4c0","outputId":"fdb1d80b-8da6-4149-a5a4-c1d31ec50311","executionInfo":{"status":"ok","timestamp":1740823982034,"user_tz":-420,"elapsed":101,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'to': 11,\n"," 'the': 10,\n"," 'study': 9,\n"," 'score': 8,\n"," 'lucky': 7,\n"," 'low': 6,\n"," 'get': 5,\n"," 'come': 4,\n"," 'more': 2,\n"," '<pad>': 1,\n"," 'you': 3,\n"," '<unk>': 0}"]},"metadata":{},"execution_count":23}],"source":["# Define tokenizer function\n","tokenizer = get_tokenizer('basic_english')\n","\n","# Create a function to yield list of tokens\n","def yield_tokens(examples):\n","    for text in examples:\n","        yield tokenizer(text)\n","\n","# Create vocabulary\n","vocab = build_vocab_from_iterator(yield_tokens(corpus),\n","                                  max_tokens=vocab_size,\n","                                  specials=[\"<unk>\", \"<pad>\"])\n","vocab.set_default_index(vocab[\"<unk>\"])\n","vocab.get_stoi()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Qcwb_J9F4aR"},"outputs":[],"source":["# Tokenize and numericalize your samples\n","def vectorize(text, vocab, sequence_length, sequence_label):\n","    tokens = tokenizer(text)\n","\n","    token_ids = [vocab[token] for token in tokens][:sequence_length]\n","    token_ids = token_ids + [vocab[\"<pad>\"]] * (sequence_length - len(tokens))\n","    sequence_label = sequence_label + [3] * (sequence_length - len(tokens))\n","    sequence_label = sequence_label[:sequence_length]\n","\n","    return torch.tensor(token_ids, dtype=torch.long), torch.tensor(sequence_label, dtype=torch.long)\n","\n","# Vectorize the samples\n","sentence_vecs = []\n","label_vecs = []\n","for sentence, labels in zip(corpus, labels):\n","    sentence_vec, labels_vec = vectorize(sentence, vocab, sequence_length, labels)\n","    sentence_vecs.append(sentence_vec)\n","    label_vecs.append(labels_vec)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sYTUNNQfF4Xh","outputId":"fd22516f-a9f4-44b4-e609-bcf2ae4532ba","executionInfo":{"status":"ok","timestamp":1740823982793,"user_tz":-420,"elapsed":19,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 3,  0,  5, 10,  6,  8])\n","tensor([ 2,  9,  2,  7,  4, 11])\n"]}],"source":["for v in sentence_vecs:\n","    print(v)"]},{"cell_type":"code","source":["for v in label_vecs:\n","    print(v)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GYxsGmXKtD5","executionInfo":{"status":"ok","timestamp":1740823983683,"user_tz":-420,"elapsed":5,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}},"outputId":"1f89198a-8396-4b26-b45f-64529ce157ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 1, 1, 2, 2, 0])\n","tensor([2, 0, 2, 2, 1, 2])\n"]}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"09tC65tojhdK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrAKhUqPjhdK","outputId":"a2e55d35-7dba-4af5-80bb-f2ecad6a1927","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740824186909,"user_tz":-420,"elapsed":15,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding weights:\n","Parameter containing:\n","tensor([[ 0.2600, -1.3100],\n","        [ 0.7200,  0.4300],\n","        [-0.6700,  0.6100],\n","        [ 0.5000,  0.5000],\n","        [-0.2600, -0.1000],\n","        [ 1.2900,  1.2500],\n","        [ 1.9500,  1.1800],\n","        [-1.4400, -1.8900],\n","        [-0.2000,  0.8800],\n","        [-0.3900,  1.0700],\n","        [ 0.3200, -0.0500],\n","        [ 0.5900, -0.9800]], requires_grad=True)\n","FC weights:\n","Parameter containing:\n","tensor([[ 0.3792,  0.4146],\n","        [ 0.4638, -0.0273],\n","        [-0.2622,  0.2486],\n","        [ 0.5454, -0.3664]], requires_grad=True)\n","FC bias:\n","Parameter containing:\n","tensor([-0.6200,  0.3700,  0.5700, -0.4800], requires_grad=True)\n"]}],"source":["class POS_Model(nn.Module):\n","    def __init__(self, vocab_size, num_classes):\n","        super().__init__()\n","        # Custom embedding layer\n","        self.embedding = nn.Embedding(vocab_size, 2)\n","        custom_embedding_weight = torch.tensor([\n","            [ 0.26, -1.31],\n","            [ 0.72,  0.43],\n","            [-0.67,  0.61],\n","            [ 0.50,  0.50],\n","            [-0.26, -0.10],\n","            [ 1.29,  1.25],\n","            [ 1.95,  1.18],\n","            [-1.44, -1.89],\n","            [-0.20,  0.88],\n","            [-0.39,  1.07],\n","            [ 0.32, -0.05],\n","            [ 0.59, -0.98]\n","        ])\n","        self.embedding.weight = nn.Parameter(custom_embedding_weight)\n","        print(\"Embedding weights:\")\n","        print(self.embedding.weight)\n","\n","        # Custom fully connected layer\n","        self.fc = nn.Linear(2, num_classes)\n","        custom_fc_weight = torch.tensor([\n","            [ 0.3792,  0.4146],\n","            [ 0.4638, -0.0273],\n","            [-0.2622,  0.2486],\n","            [ 0.5454, -0.3664],\n","        ])\n","        self.fc.weight = nn.Parameter(custom_fc_weight)\n","        custom_fc_bias = torch.tensor([-0.62,  0.37,  0.57, -0.48])\n","        self.fc.bias = nn.Parameter(custom_fc_bias)\n","\n","        print(\"FC weights:\")\n","        print(self.fc.weight)\n","        print(\"FC bias:\")\n","        print(self.fc.bias)\n","\n","    def forward(self, x):\n","        print(f\"Input shape: {x.shape}\")\n","        x = self.embedding(x)\n","        print(f\"After embedding shape: {x.shape}\")\n","        x = self.fc(x)\n","        print(f\"After FC shape: {x.shape}\")\n","        print(x)\n","        x = x.permute(0, 2, 1)\n","        print(f\"After permute shape: {x.shape}\")\n","        return x\n","\n","model = POS_Model(vocab_size, 4)"]},{"cell_type":"markdown","source":["# Forward input 1"],"metadata":{"id":"wzqMMVER0yNK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkKJb31XjhdK","outputId":"ee76cfe5-4681-4bed-b1ad-7c112b1e975a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740824221073,"user_tz":-420,"elapsed":6,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([1, 6])\n","After embedding shape: torch.Size([1, 6, 2])\n","After FC shape: torch.Size([1, 6, 4])\n","tensor([[[-0.2231,  0.5883,  0.5632, -0.3905],\n","         [-1.0645,  0.5264,  0.1762,  0.1418],\n","         [ 0.3874,  0.9342,  0.5425, -0.2344],\n","         [-0.5194,  0.5198,  0.4737, -0.2872],\n","         [ 0.6087,  1.2422,  0.3521,  0.1512],\n","         [-0.3310,  0.2532,  0.8412, -0.9115]]], grad_fn=<ViewBackward0>)\n","After permute shape: torch.Size([1, 4, 6])\n"]}],"source":["input_1 = torch.tensor([[3, 0, 5, 10, 6, 8]], dtype=torch.long)\n","label_1 = label_vecs[0]\n","\n","output = model(input_1)"]},{"cell_type":"markdown","source":["## M08POS01\n","### Câu hỏi\n","**Output** ở trong hình baseline phải có shape bằng bao nhiêu?  \n","A.\n","```\n","(1, 4, 6)\n","```\n","B.\n","```\n","(1, 6, 4)\n","```\n","C.\n","```\n","(1, 3, 6)\n","```\n","D.\n","```\n","(1, 6, 3)\n","```\n","### Đáp án\n","A  \n","*Giải thích*: Bình thường output sẽ là (batch_size, seq_len, nums_cls) nhưng vì đưa output vào nn.CrossEntropyLoss() nên bắt buổi phải permute đổi thành (batch_size, nums_cls, seq_len)"],"metadata":{"id":"ei8V1FauskOf"}},{"cell_type":"markdown","source":["# Sofmaxt output"],"metadata":{"id":"3PG2qWtE0b1R"}},{"cell_type":"code","source":["import torch\n","x = torch.tensor([[-0.2231,  0.5883,  0.5632, -0.3905],\n","         [-1.0645,  0.5264,  0.1762,  0.1418],\n","         [ 0.3874,  0.9342,  0.5425, -0.2344],\n","         [-0.5194,  0.5198,  0.4737, -0.2872],\n","         [ 0.6087,  1.2422,  0.3521,  0.1512],\n","         [-0.3310,  0.2532,  0.8412, -0.9115]])\n","\n","import numpy as np\n","def softmax(x):\n","    exp_x = np.exp(x)\n","    return exp_x / np.sum(exp_x)\n","\n","rs = softmax(x.detach().numpy())\n","result = [np.argmax(x) for x in rs]\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOacJfgwto29","executionInfo":{"status":"ok","timestamp":1741101224297,"user_tz":-420,"elapsed":16,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}},"outputId":"1724867e-e17c-489b-d2cf-f4b94feae310"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 1, 1, 1, 1, 2]\n"]}]},{"cell_type":"markdown","source":["## M08POS02\n","### Câu hỏi\n","Hãy cho biết sau khi đưa sample 1 vào model, tính toán forward, đưa vào softmax, vector dự đoán của mô hình sẽ là?  \n","A.\n","```\n","[1,1,2,2,1,1]\n","```\n","B.\n","```\n","[0,1,0,2,2,2]\n","```\n","C.\n","```\n","[0,1,2,2,1,1]\n","```\n","D.\n","```\n","[1,1,1,1,1,2]\n","```\n","### Đáp án\n","D"],"metadata":{"id":"xRwfYVA_tZLt"}},{"cell_type":"markdown","source":["# Forward input 2"],"metadata":{"id":"lcbiabO6022i"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvI6gb38jhdL","outputId":"e89635f6-6fb5-469c-b179-74109e9042e8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740733721920,"user_tz":-420,"elapsed":12,"user":{"displayName":"Nha Nguyen","userId":"05581690424976052134"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: torch.Size([1, 6])\n","After embedding shape: torch.Size([1, 6, 2])\n","After FC shape: torch.Size([1, 6, 4])\n","tensor([[[-0.6212,  0.0426,  0.8973, -1.0689],\n","         [-0.3243,  0.1599,  0.9383, -1.0848],\n","         [-0.6212,  0.0426,  0.8973, -1.0689],\n","         [-1.9496, -0.2463,  0.4777, -0.5729],\n","         [-0.7601,  0.2521,  0.6133, -0.5852],\n","         [-0.8026,  0.6704,  0.1717,  0.2009]]], grad_fn=<ViewBackward0>)\n","After permute shape: torch.Size([1, 4, 6])\n"]}],"source":["input_2 = torch.tensor([[2, 9, 2, 7, 4, 11]], dtype=torch.long)\n","label_2 = label_vecs[1]\n","\n","output = model(input_2)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}