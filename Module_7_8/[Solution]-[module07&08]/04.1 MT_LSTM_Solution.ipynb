{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "p23C1-Bfn8g6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201797,
     "status": "ok",
     "timestamp": 1740919028897,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "p23C1-Bfn8g6",
    "outputId": "5709d12f-1c4e-425c-b52c-e99d2d4b250f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.17.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: tqdm in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (4.67.1)\n",
      "Requirement already satisfied: requests in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (2.32.3)\n",
      "Requirement already satisfied: torch==2.2.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (2.2.0)\n",
      "Requirement already satisfied: numpy in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (1.26.4)\n",
      "Requirement already satisfied: torchdata==0.7.1 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchtext==0.17.0) (0.7.1)\n",
      "Requirement already satisfied: filelock in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torch==2.2.0->torchtext==0.17.0) (2024.6.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from requests->torchtext==0.17.0) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\miniconda3\\envs\\deeplearning\\lib\\site-packages (from tqdm->torchtext==0.17.0) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchtext==0.17.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22382432-34a8-474b-9519-af1168597ea1",
   "metadata": {
    "id": "22382432-34a8-474b-9519-af1168597ea1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\deeplearning\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "oh5fYa2Loxdy",
   "metadata": {
    "id": "oh5fYa2Loxdy"
   },
   "outputs": [],
   "source": [
    "# Đặt seed cho các thư viện\n",
    "def set_seed(seed_value=42):\n",
    "    torch.manual_seed(seed_value)  # Seed cho PyTorch trên CPU\n",
    "    torch.cuda.manual_seed(seed_value)  # Seed cho PyTorch trên GPU (nếu có)\n",
    "    np.random.seed(seed_value)  # Seed cho NumPy\n",
    "    random.seed(seed_value)  # Seed cho Python random\n",
    "    torch.backends.cudnn.deterministic = (\n",
    "        True  # Đảm bảo tính deterministic khi chạy trên GPU\n",
    "    )\n",
    "    torch.backends.cudnn.benchmark = False  # Tắt benchmark để giữ tính nhất quán\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6",
   "metadata": {
    "id": "7efe5b00-cda0-4c3f-9cbc-6fd590ebb4a6"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ydkk0skfpEzC",
   "metadata": {
    "id": "ydkk0skfpEzC"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a function to yield list of tokens\n",
    "\n",
    "def yield_tokens(examples):\n",
    "\n",
    "    for text in examples:\n",
    "\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JaZFIDjwoAmJ",
   "metadata": {
    "id": "JaZFIDjwoAmJ"
   },
   "source": [
    "## Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a84e42f-922c-4060-a00b-85dd862b1e6f",
   "metadata": {
    "id": "1a84e42f-922c-4060-a00b-85dd862b1e6f"
   },
   "outputs": [],
   "source": [
    "# Source corpus\n",
    "corpus_en = [\"i love you\", \"build ai model\"]\n",
    "data_size_en = len(corpus_en)\n",
    "\n",
    "vocab_size_en = 8\n",
    "sequence_length_en = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838ccb88-1930-47ba-8536-c97bb58b9fd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1740923565890,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "838ccb88-1930-47ba-8536-c97bb58b9fd1",
    "outputId": "3d58e03d-82ed-4243-f507-c38a9883845e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 6,\n",
       " '<unk>': 0,\n",
       " '<eos>': 2,\n",
       " '<pad>': 1,\n",
       " 'ai': 3,\n",
       " 'build': 4,\n",
       " 'i': 5,\n",
       " 'model': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_en = build_vocab_from_iterator(\n",
    "    yield_tokens(corpus_en),\n",
    "    max_tokens=vocab_size_en,\n",
    "    specials=[\"<unk>\", \"<pad>\", \"<eos>\"],\n",
    ")\n",
    "vocab_en.set_default_index(vocab_en[\"<unk>\"])\n",
    "vocab_en.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7aaa78c-18e0-4e05-bfed-e22b1b7194bc",
   "metadata": {
    "id": "f7aaa78c-18e0-4e05-bfed-e22b1b7194bc"
   },
   "outputs": [],
   "source": [
    "# vectorize (tokenize, numberize, padding, truncate, add special token)\n",
    "def vectorize_en(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (\n",
    "        sequence_length - len(tokens)\n",
    "    )\n",
    "    return torch.tensor(token_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c1877c-fd26-4a6f-9bd3-ff50a1e3ab0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740923566156,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "53c1877c-fd26-4a6f-9bd3-ff50a1e3ab0c",
    "outputId": "a1dc8c58-7c42-4ed0-8fd0-01df865537dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 0, 2])\n",
      "tensor([4, 3, 7, 2])\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_en = []\n",
    "for sentence in corpus_en:\n",
    "    corpus_ids_en.append(vectorize_en(sentence, vocab_en, sequence_length_en))\n",
    "\n",
    "for v in corpus_ids_en:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sUBZzERNoD_6",
   "metadata": {
    "id": "sUBZzERNoD_6"
   },
   "source": [
    "## Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164459c8-b226-447a-8a69-4a12e05e7566",
   "metadata": {
    "id": "164459c8-b226-447a-8a69-4a12e05e7566"
   },
   "outputs": [],
   "source": [
    "# Target corpus\n",
    "corpus_vn = [\"toi yeu ban\", \"xây mô hình ai\"]\n",
    "data_size_vn = len(corpus_vn)\n",
    "\n",
    "vocab_size_vn = 12\n",
    "sequence_length_vn = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740923567171,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "2726650a-52ef-4150-9b09-0071d0ce2a31",
    "outputId": "96b43359-27a8-4455-c20f-eea3796b6860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " 'hình': 6,\n",
       " 'ban': 5,\n",
       " '<eos>': 3,\n",
       " '<pad>': 1,\n",
       " '<sos>': 2,\n",
       " 'mô': 7,\n",
       " 'ai': 4,\n",
       " 'toi': 8,\n",
       " 'xây': 9,\n",
       " 'yeu': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vocabulary\n",
    "vocab_vn = build_vocab_from_iterator(\n",
    "    yield_tokens(corpus_vn),\n",
    "    max_tokens=vocab_size_vn,\n",
    "    specials=[\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"],\n",
    ")\n",
    "vocab_vn.set_default_index(vocab_vn[\"<unk>\"])\n",
    "vocab_vn.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dK4tSN-BpCmT",
   "metadata": {
    "id": "dK4tSN-BpCmT"
   },
   "outputs": [],
   "source": [
    "# vectorize (tokenize, numberize, padding, truncate, add special token)\n",
    "def vectorize_vn(text, vocab, sequence_length):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [vocab[\"<sos>\"]] + [vocab[token] for token in tokens] + [vocab[\"<eos>\"]]\n",
    "    token_ids = tokens[:sequence_length] + [vocab[\"<pad>\"]] * (\n",
    "        sequence_length - len(tokens)\n",
    "    )\n",
    "    return torch.tensor(token_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548484cb-e415-4e4f-a7f5-b0fd0ed48e59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1740923567829,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "548484cb-e415-4e4f-a7f5-b0fd0ed48e59",
    "outputId": "549518ec-ca40-41f7-afe1-ae3ef9b7adec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  8, 10,  5,  3,  1])\n",
      "tensor([2, 9, 7, 6, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the samples\n",
    "corpus_ids_vn = []\n",
    "for sentence in corpus_vn:\n",
    "    corpus_ids_vn.append(vectorize_vn(sentence, vocab_vn, sequence_length_vn))\n",
    "\n",
    "for v in corpus_ids_vn:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b547154b-2223-4e4f-a875-119ec33f9812",
   "metadata": {
    "id": "b547154b-2223-4e4f-a875-119ec33f9812"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aoOvjxY4rc-T",
   "metadata": {
    "id": "aoOvjxY4rc-T"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hxbF3PNnrl_7",
   "metadata": {
    "id": "hxbF3PNnrl_7"
   },
   "outputs": [],
   "source": [
    "# LSTM Encoder\n",
    "class LSTM_Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [batch_size, seq_len]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded: [batch_size, seq_len, emb_dim]\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        # outputs: [batch_size, seq_len, hid_dim]\n",
    "        # hidden, cell: [n_layers, batch_size, hid_dim]\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f8Ig93ZrmCj",
   "metadata": {
    "id": "6f8Ig93ZrmCj"
   },
   "outputs": [],
   "source": [
    "# LSTM Decoder\n",
    "class LSTM_Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input: [batch_size]\n",
    "        input = input.unsqueeze(1)  # [batch_size, 1]\n",
    "        embedded = self.dropout(self.embedding(input))  # [batch_size, 1, emb_dim]\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        # output: [batch_size, 1, hid_dim]\n",
    "        prediction = self.fc_out(output.squeeze(1))  # [batch_size, output_dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pphPlSBurmEv",
   "metadata": {
    "id": "pphPlSBurmEv"
   },
   "outputs": [],
   "source": [
    "# LSTM Seq2Seq Model\n",
    "class LSTM_Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]  # <sos> token\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t, :] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dtw6QSA0oZS7",
   "metadata": {
    "id": "dtw6QSA0oZS7"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7cb8b50-51a1-43b1-9d2d-569c269e3ee5",
   "metadata": {
    "id": "f7cb8b50-51a1-43b1-9d2d-569c269e3ee5"
   },
   "outputs": [],
   "source": [
    "# Training Code\n",
    "def train_model(model, train_iterator, optimizer, criterion, clip=1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for src, trg in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(train_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eTNJ5-EKr-yE",
   "metadata": {
    "id": "eTNJ5-EKr-yE"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "FgCNflkqsAbz",
   "metadata": {
    "id": "FgCNflkqsAbz"
   },
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vRcg0ktpsBoc",
   "metadata": {
    "id": "vRcg0ktpsBoc"
   },
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "enc_lstm = LSTM_Encoder(vocab_size_en, 256, 512, 2, 0.5)\n",
    "dec_lstm = LSTM_Decoder(vocab_size_vn, 256, 512, 2, 0.5)\n",
    "lstm_model = LSTM_Seq2Seq(enc_lstm, dec_lstm, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "z6Zk3xPGsGHE",
   "metadata": {
    "id": "z6Zk3xPGsGHE"
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer_lstm = torch.optim.Adam(lstm_model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab_vn[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1367b830-30f1-43e1-bef1-e896633345ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 31075,
     "status": "ok",
     "timestamp": 1740923603621,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "1367b830-30f1-43e1-bef1-e896633345ae",
    "outputId": "ec2dc5d2-7cef-4ab0-a83f-1e4fd715384b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tLSTM Loss: 2.490\n",
      "Epoch: 02\n",
      "\tLSTM Loss: 2.442\n",
      "Epoch: 03\n",
      "\tLSTM Loss: 2.360\n",
      "Epoch: 04\n",
      "\tLSTM Loss: 2.270\n",
      "Epoch: 05\n",
      "\tLSTM Loss: 2.075\n",
      "Epoch: 06\n",
      "\tLSTM Loss: 1.847\n",
      "Epoch: 07\n",
      "\tLSTM Loss: 1.493\n",
      "Epoch: 08\n",
      "\tLSTM Loss: 1.183\n",
      "Epoch: 09\n",
      "\tLSTM Loss: 0.905\n",
      "Epoch: 10\n",
      "\tLSTM Loss: 0.760\n",
      "Epoch: 11\n",
      "\tLSTM Loss: 0.596\n",
      "Epoch: 12\n",
      "\tLSTM Loss: 0.486\n",
      "Epoch: 13\n",
      "\tLSTM Loss: 0.373\n",
      "Epoch: 14\n",
      "\tLSTM Loss: 0.286\n",
      "Epoch: 15\n",
      "\tLSTM Loss: 0.246\n",
      "Epoch: 16\n",
      "\tLSTM Loss: 0.173\n",
      "Epoch: 17\n",
      "\tLSTM Loss: 0.155\n",
      "Epoch: 18\n",
      "\tLSTM Loss: 0.109\n",
      "Epoch: 19\n",
      "\tLSTM Loss: 0.088\n",
      "Epoch: 20\n",
      "\tLSTM Loss: 0.075\n",
      "Epoch: 21\n",
      "\tLSTM Loss: 0.053\n",
      "Epoch: 22\n",
      "\tLSTM Loss: 0.046\n",
      "Epoch: 23\n",
      "\tLSTM Loss: 0.059\n",
      "Epoch: 24\n",
      "\tLSTM Loss: 0.031\n",
      "Epoch: 25\n",
      "\tLSTM Loss: 0.025\n",
      "Epoch: 26\n",
      "\tLSTM Loss: 0.035\n",
      "Epoch: 27\n",
      "\tLSTM Loss: 0.025\n",
      "Epoch: 28\n",
      "\tLSTM Loss: 0.016\n",
      "Epoch: 29\n",
      "\tLSTM Loss: 0.013\n",
      "Epoch: 30\n",
      "\tLSTM Loss: 0.012\n",
      "Epoch: 31\n",
      "\tLSTM Loss: 0.012\n",
      "Epoch: 32\n",
      "\tLSTM Loss: 0.011\n",
      "Epoch: 33\n",
      "\tLSTM Loss: 0.010\n",
      "Epoch: 34\n",
      "\tLSTM Loss: 0.007\n",
      "Epoch: 35\n",
      "\tLSTM Loss: 0.006\n",
      "Epoch: 36\n",
      "\tLSTM Loss: 0.007\n",
      "Epoch: 37\n",
      "\tLSTM Loss: 0.005\n",
      "Epoch: 38\n",
      "\tLSTM Loss: 0.005\n",
      "Epoch: 39\n",
      "\tLSTM Loss: 0.005\n",
      "Epoch: 40\n",
      "\tLSTM Loss: 0.004\n",
      "Epoch: 41\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 42\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 43\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 44\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 45\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 46\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 47\n",
      "\tLSTM Loss: 0.003\n",
      "Epoch: 48\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 49\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 50\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 51\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 52\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 53\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 54\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 55\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 56\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 57\n",
      "\tLSTM Loss: 0.002\n",
      "Epoch: 58\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 59\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 60\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 61\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 62\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 63\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 64\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 65\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 66\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 67\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 68\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 69\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 70\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 71\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 72\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 73\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 74\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 75\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 76\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 77\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 78\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 79\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 80\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 81\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 82\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 83\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 84\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 85\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 86\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 87\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 88\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 89\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 90\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 91\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 92\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 93\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 94\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 95\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 96\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 97\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 98\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 99\n",
      "\tLSTM Loss: 0.001\n",
      "Epoch: 100\n",
      "\tLSTM Loss: 0.001\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_data = list(zip(corpus_ids_en, corpus_ids_vn))\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, batch_size=2)\n",
    "N_EPOCHS = 100\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    # Train LSTM\n",
    "    lstm_loss = train_model(lstm_model, train_iterator, optimizer_lstm, criterion)\n",
    "\n",
    "    print(f\"Epoch: {epoch+1:02}\")\n",
    "    print(f\"\\tLSTM Loss: {lstm_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0GfSSXOMtOJU",
   "metadata": {
    "id": "0GfSSXOMtOJU"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nOyMKelVsecz",
   "metadata": {
    "id": "nOyMKelVsecz"
   },
   "outputs": [],
   "source": [
    "# Testing/Inference Code\n",
    "def translate_sentence(\n",
    "    model, sentence, src_vocab, trg_vocab, max_len, device, is_transformer=False\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = (\n",
    "        vectorize_en(sentence, src_vocab, sequence_length_en).unsqueeze(0).to(device)\n",
    "    )\n",
    "    output_encoder = None\n",
    "    hidden_encoder = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # LSTM inference\n",
    "        hidden, cell = model.encoder(tokens)\n",
    "        trg_indexes = [trg_vocab[\"<sos>\"]]\n",
    "        for i in range(max_len):\n",
    "            trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indexes.append(pred_token)\n",
    "            output_encoder = output\n",
    "            hidden_encoder = (hidden, cell)\n",
    "            if pred_token == trg_vocab[\"<eos>\"]:\n",
    "                break\n",
    "\n",
    "    trg_tokens = [trg_vocab.get_itos()[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:-1], output_encoder, hidden_encoder  # Remove <sos>, <eos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8hGnwmS-tQG8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1740923603711,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "8hGnwmS-tQG8",
    "outputId": "6173719f-d3a9-40d9-afc7-5ddb5882ea5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: i love you\n",
      "LSTM Translation: toi yeu ban\n"
     ]
    }
   ],
   "source": [
    "# Test the models\n",
    "test_sentence = \"i love you\"\n",
    "print(\"Original:\", test_sentence)\n",
    "\n",
    "lstm_translation, output_encoder, _ = translate_sentence(\n",
    "    lstm_model, test_sentence, vocab_en, vocab_vn, sequence_length_vn, device\n",
    ")\n",
    "print(\"LSTM Translation:\", \" \".join(lstm_translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KPeraH4EvWdD",
   "metadata": {
    "id": "KPeraH4EvWdD"
   },
   "source": [
    "# Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "AOj2e3Ahu9RX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740923603716,
     "user": {
      "displayName": "Nha Nguyen",
      "userId": "05581690424976052134"
     },
     "user_tz": -420
    },
    "id": "AOj2e3Ahu9RX",
    "outputId": "a1600dd3-f7fb-4728-9a75-f2524b27c930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.5159)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum output of decoder\n",
    "sum(output_encoder[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Xw-gzA9uGFb",
   "metadata": {
    "id": "8Xw-gzA9uGFb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
