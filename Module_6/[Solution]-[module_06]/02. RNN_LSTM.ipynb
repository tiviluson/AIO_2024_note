{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qrOnSV6rspk"
   },
   "source": [
    "# Define RNN Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBIZgNsPrspm"
   },
   "source": [
    "RNN: Giả sử sample X = [3, 3] => Mỗi x_t = [1, 3]\n",
    "1. Tính output của lớp hidden layer (có bias), với d_h = 2.\n",
    "2. Tính output của model ở lớp cuối cùng, với d_out = 1. (regression).\n",
    "3. Chuyển bài toán thành bài toán Sequence Labeling, tính output của từng time-steps.\n",
    "<!-- 4. Bidirectional RNN, đưa ra output cuối cùng. -->\n",
    "\n",
    "LSTM: Không làm bias, quá phức tạp.\n",
    "1. Tính forget gate.\n",
    "2. Tính add gate.\n",
    "3. Tính output gate.\n",
    "4. Tính final output.\n",
    "<!-- 4. Stacked LSTM với hàm kích hoạt RELU. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5635,
     "status": "ok",
     "timestamp": 1735983586134,
     "user": {
      "displayName": "Thịnh Nguyễn Phúc",
      "userId": "12488191851066020842"
     },
     "user_tz": -420
    },
    "id": "QEDydC6trspn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
    "        super(RNNCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        if nonlinearity not in [\"tanh\", \"relu\"]:\n",
    "            raise ValueError(\"Invalid nonlinearity. Choose 'tanh' or 'relu'.\")\n",
    "\n",
    "        self.nonlinearity = nonlinearity\n",
    "\n",
    "        # Linear transformations\n",
    "        self.input_to_hidden = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.hidden_to_hidden = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "    def set_weights(\n",
    "        self,\n",
    "        input_to_hidden_weight,\n",
    "        hidden_to_hidden_weight,\n",
    "        input_to_hidden_bias,\n",
    "        hidden_to_hidden_bias,\n",
    "    ):\n",
    "        self.input_to_hidden.weight.data = input_to_hidden_weight\n",
    "        self.hidden_to_hidden.weight.data = hidden_to_hidden_weight\n",
    "        self.input_to_hidden.bias.data = input_to_hidden_bias\n",
    "        self.hidden_to_hidden.bias.data = hidden_to_hidden_bias\n",
    "\n",
    "    def forward(self, input, hidden_state_input=None):\n",
    "        if hidden_state_input is None:\n",
    "            hidden_state_input = input.new_zeros(\n",
    "                input.size(0), self.hidden_size, requires_grad=False\n",
    "            )\n",
    "\n",
    "        # Compute the new hidden state\n",
    "        hidden_state = self.input_to_hidden(input) + self.hidden_to_hidden(\n",
    "            hidden_state_input\n",
    "        )\n",
    "        hidden_state = (\n",
    "            torch.tanh(hidden_state)\n",
    "            if self.nonlinearity == \"tanh\"\n",
    "            else torch.relu(hidden_state)\n",
    "        )\n",
    "\n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 444,
     "status": "ok",
     "timestamp": 1735983590341,
     "user": {
      "displayName": "Thịnh Nguyễn Phúc",
      "userId": "12488191851066020842"
     },
     "user_tz": -420
    },
    "id": "4HaxqVpkrspn",
    "outputId": "2031cd01-9523-4611-9f80-67ca4add512e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the hidden state at time step 0: \n",
      "tensor([[0.9866, 0.9051]])\n",
      "Output of the hidden state at time step 1: \n",
      "tensor([[0.0946, 0.9702]])\n",
      "Output of the hidden state at time step 2: \n",
      "tensor([[-0.8996,  0.9983]])\n"
     ]
    }
   ],
   "source": [
    "#  1. Tính output của lớp hidden layer (có bias), với d_h = 2.\n",
    "X = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n",
    "\n",
    "torch.manual_seed(42)\n",
    "rnn = RNNCell(input_size=3, hidden_size=2)\n",
    "\n",
    "input_to_hidden_weight = torch.tensor([[-1.0, 0.0, 0.5], [1.0, 0.0, -0.5]])\n",
    "input_to_hidden_bias = torch.tensor([1.0])\n",
    "hidden_to_hidden_weight = torch.tensor([[0.0, -1.0]])\n",
    "hidden_to_hidden_bias = torch.tensor([1.0])\n",
    "\n",
    "rnn.set_weights(\n",
    "    input_to_hidden_weight,\n",
    "    hidden_to_hidden_weight,\n",
    "    input_to_hidden_bias,\n",
    "    hidden_to_hidden_bias,\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Output of the hidden state\n",
    "    hidden_state = None\n",
    "    for i in range(3):\n",
    "        hidden_state = rnn(X[i].unsqueeze(0), hidden_state)\n",
    "        print(\n",
    "            \"Output of the hidden state at time step {}: \\n{}\".format(i, hidden_state)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9866, 0.9051]])\n",
      "tensor([[0.0946, 0.9702]])\n",
      "tensor([[-0.8996,  0.9983]])\n"
     ]
    }
   ],
   "source": [
    "Wxh = torch.tensor([[-1.0, 0.0, 0.5], [1.0, 0.0, -0.5]])\n",
    "bxh = torch.tensor([1.0])\n",
    "Whh = torch.tensor([[0.0, -1.0], [0.0, -1.0]])\n",
    "bhh = torch.tensor([1.0])\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n",
    "h = torch.tensor([[0.0, 0.0]])\n",
    "for i in range(3):\n",
    "    # Compute the new hidden state using the RNN cell formula\n",
    "    h = torch.tanh(x[i] @ Wxh.T + h @ Whh.T + bxh + bhh)\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9866,  0.9051],\n",
       "         [ 0.0946,  0.9702],\n",
       "         [-0.8996,  0.9983]], grad_fn=<SqueezeBackward1>),\n",
       " torch.Size([3, 2]),\n",
       " tensor([[-0.8996,  0.9983]], grad_fn=<SqueezeBackward1>),\n",
       " torch.Size([1, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = torch.nn.RNN(\n",
    "    input_size=3,\n",
    "    hidden_size=2,\n",
    "    bias=True,\n",
    "    nonlinearity=\"tanh\",\n",
    ")\n",
    "\n",
    "rnn.weight_ih_l0 = torch.nn.Parameter(Wxh)\n",
    "rnn.weight_hh_l0 = torch.nn.Parameter(Whh)\n",
    "rnn.bias_ih_l0 = torch.nn.Parameter(bxh)\n",
    "rnn.bias_hh_l0 = torch.nn.Parameter(bhh)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])\n",
    "output, hn = rnn(x)\n",
    "output, output.shape, hn, hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1377,
     "status": "ok",
     "timestamp": 1735983595711,
     "user": {
      "displayName": "Thịnh Nguyễn Phúc",
      "userId": "12488191851066020842"
     },
     "user_tz": -420
    },
    "id": "2QgBnW5nrspo",
    "outputId": "c7574260-2e55-459a-b415-5534b7354548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final hidden state: \n",
      "tensor([[-0.8996,  0.9983]])\n",
      "Output: \n",
      "tensor([[0.9983]])\n"
     ]
    }
   ],
   "source": [
    "# 2. Tính output của model ở lớp cuối cùng, với d_out = 1. (regression).\n",
    "hidden_state = torch.tensor([[-0.8996, 0.9983]])\n",
    "print(\"Final hidden state: \\n{}\".format(hidden_state))\n",
    "\n",
    "hidden_to_output = nn.Linear(2, 1, bias=True)\n",
    "hidden_to_output.weight.data = torch.tensor([[0.0, 1.0]])\n",
    "hidden_to_output.bias.data = torch.tensor([0.0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = hidden_to_output(hidden_state)\n",
    "    print(\"Output: \\n{}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8996,  0.9983], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9983, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.tensor([0.0, 1.0])\n",
    "b = torch.tensor(0.0)\n",
    "W @ hn.squeeze() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvOmS_XLrspo",
    "outputId": "892ff7a8-9b19-4af3-8cc1-7c26b1b64b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Output of the hidden state at time step 0: \n",
      "tensor([[0.9866, 0.9051]])\n",
      "Output at time step 0: \n",
      "tensor([[0.4796, 0.5204]])\n",
      "Predicted label at time step 0: \n",
      "tensor([1])\n",
      "*************************\n",
      "Output of the hidden state at time step 1: \n",
      "tensor([[0.0946, 0.9702]])\n",
      "Output at time step 1: \n",
      "tensor([[0.7059, 0.2941]])\n",
      "Predicted label at time step 1: \n",
      "tensor([0])\n",
      "*************************\n",
      "Output of the hidden state at time step 2: \n",
      "tensor([[-0.8996,  0.9983]])\n",
      "Output at time step 2: \n",
      "tensor([[0.8697, 0.1303]])\n",
      "Predicted label at time step 2: \n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# 3. Chuyển bài toán thành bài toán Sequence Labeling, tính output của từng time-steps.\n",
    "# Giả sử mỗi hàng là một embedding của một từ trong câu, và mỗi từ được gán nhãn 0 hoặc 1.\n",
    "\n",
    "hidden_to_output = nn.Linear(2, 2, bias=True)\n",
    "hidden_to_output.weight.data = torch.tensor([[0.0, 1.0], [1.0, 0.0]])\n",
    "hidden_to_output.bias.data = torch.tensor([0.0])\n",
    "\n",
    "hidden_state = None\n",
    "with torch.no_grad():\n",
    "    for i in range(3):\n",
    "        print(25 * \"*\")\n",
    "        hidden_state = rnn(X[i].unsqueeze(0), hidden_state)\n",
    "        print(\n",
    "            \"Output of the hidden state at time step {}: \\n{}\".format(i, hidden_state)\n",
    "        )\n",
    "        output = nn.Softmax(dim=1)(hidden_to_output(hidden_state))\n",
    "        print(\"Output at time step {}: \\n{}\".format(i, output))\n",
    "        print(\n",
    "            \"Predicted label at time step {}: \\n{}\".format(\n",
    "                i, torch.argmax(output, dim=1)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9051,  0.9702,  0.9983],\n",
       "        [ 0.9866,  0.0946, -0.8996]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.tensor([[0.0, 1.0], [1.0, 0.0]])\n",
    "b = torch.tensor([0.0, 0.0])\n",
    "W @ output.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gC2B2Mcerspp",
    "outputId": "1be6d38d-a47f-48f8-8c89-f96a1fba5166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "Output of the hidden state at time step 0: \n",
      "tensor([[0.9866, 0.9051]])\n",
      "Output of the hidden state at time step 0: \n",
      "tensor([[-0.4621,  0.9998]])\n",
      "Output at time step 0: \n",
      "tensor([[3.4294]])\n",
      "*************************\n",
      "Output of the hidden state at time step 1: \n",
      "tensor([[0.0946, 0.9702]])\n",
      "Output of the hidden state at time step 1: \n",
      "tensor([[2.4676e-04, 9.6404e-01]])\n",
      "Output at time step 1: \n",
      "tensor([[3.0290]])\n",
      "*************************\n",
      "Output of the hidden state at time step 2: \n",
      "tensor([[-0.8996,  0.9983]])\n",
      "Output of the hidden state at time step 2: \n",
      "tensor([[0.9114, 0.4899]])\n",
      "Output at time step 2: \n",
      "tensor([[2.5000]])\n"
     ]
    }
   ],
   "source": [
    "# 4. Bidirectional RNN, đưa ra output cuối cùng.\n",
    "# Giá trị trọng số 2 mạng là như nhau, tính output của model ở lớp cuối cùng.\n",
    "forward_rnn = RNNCell(input_size=3, hidden_size=2)\n",
    "backward_rnn = RNNCell(input_size=3, hidden_size=2)\n",
    "\n",
    "forward_rnn.set_weights(\n",
    "    input_to_hidden_weight,\n",
    "    hidden_to_hidden_weight,\n",
    "    input_to_hidden_bias,\n",
    "    hidden_to_hidden_bias,\n",
    ")\n",
    "backward_rnn.set_weights(\n",
    "    input_to_hidden_weight,\n",
    "    hidden_to_hidden_weight,\n",
    "    input_to_hidden_bias,\n",
    "    hidden_to_hidden_bias,\n",
    ")\n",
    "\n",
    "hidden_to_output = nn.Linear(4, 1, bias=True)\n",
    "hidden_to_output.weight.data = torch.tensor([[1.0, 1.0, 1.0, 1.0]])\n",
    "hidden_to_output.bias.data = torch.tensor([1.0])\n",
    "\n",
    "hidden_state_forward = None\n",
    "hidden_state_backward = None\n",
    "with torch.no_grad():\n",
    "    for i in range(3):\n",
    "        print(25 * \"*\")\n",
    "        hidden_state_forward = forward_rnn(X[i].unsqueeze(0), hidden_state_forward)\n",
    "        hidden_state_backward = backward_rnn(\n",
    "            X[2 - i].unsqueeze(0), hidden_state_backward\n",
    "        )\n",
    "        print(\n",
    "            \"Output of the hidden state at time step {}: \\n{}\".format(\n",
    "                i, hidden_state_forward\n",
    "            )\n",
    "        )\n",
    "        print(\n",
    "            \"Output of the hidden state at time step {}: \\n{}\".format(\n",
    "                i, hidden_state_backward\n",
    "            )\n",
    "        )\n",
    "        hidden_state = torch.cat((hidden_state_forward, hidden_state_backward), dim=1)\n",
    "        output = hidden_to_output(hidden_state)\n",
    "        print(\"Output at time step {}: \\n{}\".format(i, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8996,  0.9983], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_b = torch.tensor([[0.9114, 0.4899]])\n",
    "hn_cat = torch.cat((hn.squeeze(), hn_b.squeeze()), dim=0)\n",
    "torch.ones((1, 4)) @ hn_cat + torch.tensor(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYFpeuy7rspp"
   },
   "source": [
    "# Define LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRgXBTuxrspq"
   },
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=False):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "\n",
    "        # Linear layers for input-to-hidden and hidden-to-hidden transformations\n",
    "        self.hidden_to_forget = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        self.hidden_to_input = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        self.hidden_to_cell = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
    "\n",
    "        self.input_to_forget = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.input_to_input = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.input_to_cell = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.input_to_output = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "\n",
    "    def set_weights(\n",
    "        self,\n",
    "        input_to_forget_weight,\n",
    "        input_to_input_weight,\n",
    "        input_to_cell_weight,\n",
    "        input_to_output_weight,\n",
    "        hidden_to_forget_weight,\n",
    "        hidden_to_input_weight,\n",
    "        hidden_to_cell_weight,\n",
    "        hidden_to_output_weight,\n",
    "    ):\n",
    "        self.input_to_forget.weight.data = input_to_forget_weight\n",
    "        self.input_to_input.weight.data = input_to_input_weight\n",
    "        self.input_to_cell.weight.data = input_to_cell_weight\n",
    "        self.input_to_output.weight.data = input_to_output_weight\n",
    "\n",
    "        self.hidden_to_forget.weight.data = hidden_to_forget_weight\n",
    "        self.hidden_to_input.weight.data = hidden_to_input_weight\n",
    "        self.hidden_to_cell.weight.data = hidden_to_cell_weight\n",
    "        self.hidden_to_output.weight.data = hidden_to_output_weight\n",
    "\n",
    "    def forward(self, input, hidden_state_tuple=None):\n",
    "        # If hidden state is not provided, initialize it to zeros (the first time step)\n",
    "        if hidden_state_tuple is None:\n",
    "            hidden_state_tuple = input.new_zeros(\n",
    "                input.size(0), self.hidden_size, requires_grad=False\n",
    "            )\n",
    "            hidden_state_tuple = (hidden_state_tuple, hidden_state_tuple)\n",
    "\n",
    "        hidden_state, cell_state_prev = hidden_state_tuple\n",
    "\n",
    "        # Compute gates\n",
    "        input_gate = self.input_to_input(input) + self.hidden_to_input(\n",
    "            hidden_state\n",
    "        )  # Add gate\n",
    "        forget_gate = self.input_to_forget(input) + self.hidden_to_forget(\n",
    "            hidden_state\n",
    "        )  # Forget gate\n",
    "        cell_gate = self.input_to_cell(input) + self.hidden_to_cell(hidden_state)\n",
    "        output_gate = self.input_to_output(input) + self.hidden_to_output(\n",
    "            hidden_state\n",
    "        )  # Output gate\n",
    "\n",
    "        print(\"Input gate: \\n{}\".format(input_gate))\n",
    "        print(\"Forget gate: \\n{}\".format(forget_gate))\n",
    "        print(\"Cell gate: \\n{}\".format(cell_gate))\n",
    "\n",
    "        # Apply nonlinearities\n",
    "        i_t = torch.sigmoid(input_gate)\n",
    "        f_t = torch.sigmoid(forget_gate)\n",
    "        g_t = torch.tanh(cell_gate)\n",
    "        o_t = torch.sigmoid(output_gate)\n",
    "\n",
    "        # Update cell state and hidden state\n",
    "        # k_t = f_t * cell_state_prev\n",
    "        # j_t = i_t * g_t\n",
    "        cell_state_next = f_t * cell_state_prev + i_t * g_t\n",
    "        hidden_state_next = o_t * torch.tanh(cell_state_next)\n",
    "\n",
    "        return hidden_state_next, cell_state_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sK3tO8Lprspq",
    "outputId": "01226d15-727a-4064-cb0d-7c688828480f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "Input gate: \n",
      "tensor([[ 0.5000, -2.5000]])\n",
      "Forget gate: \n",
      "tensor([[ 2.5000, -0.5000]])\n",
      "Cell gate: \n",
      "tensor([[-0.5000, -0.5000]])\n",
      "Output of the hidden state at time step 0: \n",
      "tensor([[-0.2769, -0.0027]])\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTMCell(input_size=3, hidden_size=2)\n",
    "classification = nn.Linear(2, 1, bias=True)\n",
    "\n",
    "input_to_forget_weight = torch.tensor([[1.0, 0.0, 0.5], [1.0, 0.0, -0.5]])\n",
    "input_to_input_weight = torch.tensor([[-1.0, 0.0, 0.5], [-1.0, 0.0, -0.5]])\n",
    "input_to_cell_weight = torch.tensor([[1.0, 0.0, -0.5], [1.0, 0.0, -0.5]])\n",
    "input_to_output_weight = torch.tensor([[1.0, 1.0, 0.5], [1.0, -1.0, -0.5]])\n",
    "\n",
    "hidden_to_forget_weight = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "hidden_to_input_weight = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "hidden_to_cell_weight = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "hidden_to_output_weight = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "\n",
    "lstm.set_weights(\n",
    "    input_to_forget_weight,\n",
    "    input_to_input_weight,\n",
    "    input_to_cell_weight,\n",
    "    input_to_output_weight,\n",
    "    hidden_to_forget_weight,\n",
    "    hidden_to_input_weight,\n",
    "    hidden_to_cell_weight,\n",
    "    hidden_to_output_weight,\n",
    ")\n",
    "\n",
    "hidden_state_tuple = None\n",
    "with torch.no_grad():\n",
    "    print(25 * \"#\")\n",
    "    hidden_state_tuple = lstm(X[0].unsqueeze(0), hidden_state_tuple)\n",
    "    print(\n",
    "        \"Output of the hidden state at time step 0: \\n{}\".format(hidden_state_tuple[0])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([8, 3])\n",
      "weight_hh_l0 torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "lstm = torch.nn.LSTM(input_size=3, hidden_size=2, bias=False)\n",
    "\n",
    "for k, v in lstm.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxf = torch.tensor([[1.0, 0.0, 0.5], [1.0, 0.0, -0.5]])\n",
    "Whf = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "Wxi = torch.tensor([[-1.0, 0.0, 0.5], [-1.0, 0.0, -0.5]])\n",
    "Whi = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "Wxc = torch.tensor([[1.0, 0.0, -0.5], [1.0, 0.0, -0.5]])\n",
    "Whc = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "Wxo = torch.tensor([[1.0, 1.0, 0.5], [1.0, -1.0, -0.5]])\n",
    "Who = torch.tensor([[0.0, 1.0], [0.0, -1.0]])\n",
    "\n",
    "C_t_minus_1 = torch.tensor([[0.0, 0.0]])\n",
    "x_t = torch.tensor([[1.0, 2.0, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5000, -2.5000]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f_t := x_t @ Wxf.T + C_t_minus_1 @ Whf.T)\n",
    "(i_t := x_t @ Wxi.T + C_t_minus_1 @ Whi.T)\n",
    "(g_t := x_t @ Wxc.T + C_t_minus_1 @ Whc.T)\n",
    "(o_t := x_t @ Wxo.T + C_t_minus_1 @ Who.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.5000, -0.5000]]),\n",
       " tensor([[ 0.5000, -2.5000]]),\n",
       " tensor([[-0.5000, -0.5000]]),\n",
       " tensor([[ 4.5000, -2.5000]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_t, i_t, g_t, o_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_t = torch.sigmoid(f_t)\n",
    "i_t = torch.sigmoid(i_t)\n",
    "g_t = torch.tanh(g_t)\n",
    "o_t = torch.sigmoid(o_t)\n",
    "c_t = f_t * C_t_minus_1 + i_t * g_t\n",
    "h_t = o_t * torch.tanh(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2769, -0.0027]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
